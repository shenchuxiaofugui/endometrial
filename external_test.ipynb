{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from maskdilation import direct_dilation, extracted_features\n",
    "from run_radiomics import merge_label_feature\n",
    "from select_test_feature import merge_all\n",
    "from RJSNRadiomicsFeatureExtractor import main_run\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from select_test_feature import external\n",
    "tasks = [\"LNM\", \"LVSI\"]\n",
    "dilation = {\"LVSI\":{\"DWI\": 5, \"T1CE\": 6, \"T2\": 3}, \"LNM\" :{\"DWI\": 9, \"T1CE\": 9, \"T2\": 7}}\n",
    "modals = [\"DWI\", \"T1CE\", \"T2\"]\n",
    "splits = [\"intra\", \"merge\", \"peri\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:10<00:00,  4.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# mask dilation\n",
    "spacing_path = \"/homes/syli/dataset/EC_all/outside/new_1.5T/clear_up_spacing\"\n",
    "direct_dilation(spacing_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra features\n",
    "df_path = \"/homes/syli/dataset/EC_all/outside/new_1.5T/dataframe\"\n",
    "for modal in modals:\n",
    "    save_path = os.path.join(df_path, modal)\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    for i in tqdm([3, 5, 6,7,9]):\n",
    "        save = os.path.join(save_path, f\"{modal}_{i}_features.csv\")\n",
    "        main_run(\"/homes/syli/dataset/EC_all/outside/new_1.5T/clear_up_spacing\", f\"{modal}_trans\", f\"{modal}_dilation_{i}.nii.gz\", save)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先找到对应文件，进行zscore, 再merge,\n",
    "root = \"/homes/syli/dataset/EC_all/outside\"\n",
    "clinical_path = root+\"/1.5 new needed.xlsx\"\n",
    "def zscore(data, zscore_df):\n",
    "    data.iloc[:, 1:] = (data.iloc[:, 1:] - zscore_df.loc[\"mean\"]) / zscore_df.loc[\"std\"]\n",
    "    return data\n",
    "for task in tasks:\n",
    "    for modal in modals:\n",
    "        os.makedirs(root+f\"/{task}/{modal}/intra\", exist_ok=True)\n",
    "        os.makedirs(root+f\"/{task}/{modal}/peri\", exist_ok=True)\n",
    "        os.makedirs(root+f\"/{task}/{modal}/merge\", exist_ok=True)\n",
    "        zscore_df = pd.read_csv(f\"/homes/syli/dataset/EC_all/{task}_model/liuzhou_split/{modal}/dilation_{dilation[task][modal]}/mean_std.csv\", index_col=0)\n",
    "        data = pd.read_csv(df_path+f\"/{modal}/{modal}_{dilation[task][modal]}_features.csv\")\n",
    "        features = [i.replace(\"trans\", f\"resampled.nii\") for i in list(data)]\n",
    "        data.columns = features\n",
    "        liuzhou_df = zscore(data, zscore_df)\n",
    "        liuzhou_df.to_csv(root+f\"/{task}/{modal}/peri/zscore_features.csv\")\n",
    "\n",
    "        zscore_df = pd.read_csv(f\"/homes/syli/dataset/EC_all/{task}_model/liunei/{modal}/mean_std.csv\", index_col=0)\n",
    "        data = pd.read_csv(df_path+f\"/{modal}_features.csv\")\n",
    "        features = [i.replace(\"trans\", f\"resampled.nii\") for i in list(data)]\n",
    "        data.columns = features\n",
    "        liunei_df = zscore(data, zscore_df)\n",
    "        liunei_df.to_csv(root+f\"/{task}/{modal}/intra/zscore_features.csv\")\n",
    "\n",
    "        features = [i.replace(\"resampled.nii\", f\"dilation_{dilation[task][modal]}\") for i in list(liuzhou_df)]\n",
    "        liuzhou_df.columns = features\n",
    "        liunei_df[\"CaseName\"] = liunei_df[\"CaseName\"].astype(dtype=\"str\")\n",
    "        liuzhou_df[\"CaseName\"] = liuzhou_df[\"CaseName\"].astype(dtype=\"str\")\n",
    "        sum_df = pd.merge(liunei_df, liuzhou_df, on=[\"CaseName\"], validate=\"one_to_one\")\n",
    "        modal_store = root+f\"/{task}/{modal}/merge\"\n",
    "        sum_df.to_csv(os.path.join(modal_store, \"zscore_features.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "clinical_df = pd.read_excel(clinical_path)\n",
    "clinical_df[\"CaseName\"] = clinical_df[\"CaseName\"].astype(dtype=\"str\")\n",
    "clinical_df[\"CaseName\"] = [i.strip() for i in clinical_df[\"CaseName\"].values]\n",
    "print(len(clinical_df))\n",
    "for key in tasks:\n",
    "    for modal in modals:\n",
    "        for split in [\"intra\", \"peri\", \"merge\"]:\n",
    "            store_path = os.path.join(root, key, modal, split)\n",
    "            df = pd.read_csv(os.path.join(store_path, f\"zscore_features.csv\"))\n",
    "            df[\"CaseName\"] = df[\"CaseName\"].astype(dtype=\"str\")\n",
    "            df[\"CaseName\"] = [i.strip() for i in df[\"CaseName\"].values]\n",
    "            new_df = pd.merge(clinical_df[[\"CaseName\", key]], df)\n",
    "            print(len(new_df))\n",
    "            new_df.rename(columns={key: \"label\"}, inplace=True)\n",
    "            new_df.to_csv(os.path.join(store_path, f\"external_test.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task in tasks:\n",
    "    for modal in modals:\n",
    "        for split in splits:\n",
    "            external(os.path.join(root, task, modal, split, \"external_test.csv\"), \n",
    "                    os.path.join(\"/homes/syli/dataset/EC_all/result\", task, modal, split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task in tasks:\n",
    "    for i in splits:    \n",
    "        flag = True\n",
    "        for modal in modals:\n",
    "            pred_df = pd.read_csv(os.path.join(root, task, modal, i, \"external_prediction.csv\"))\n",
    "            pred_df.rename(columns={\"Pred\": f\"{modal}_prediction\"}, inplace=True)\n",
    "            if flag:\n",
    "                new_df = pred_df\n",
    "                flag = False\n",
    "            else:\n",
    "                new_df = pd.merge(new_df, pred_df, on=[\"CaseName\", \"label\"])\n",
    "        os.makedirs(os.path.join(root, task, \"combine\", i), exist_ok=True)\n",
    "        new_df.to_csv(os.path.join(root, task, \"combine\", i, \"external_features.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LNM\n",
      "intra\n",
      "merge\n",
      "peri\n",
      "LVSI\n",
      "intra\n",
      "merge\n",
      "peri\n"
     ]
    }
   ],
   "source": [
    "for task in tasks:\n",
    "    print(task)\n",
    "    for split in splits:\n",
    "        print(split)\n",
    "        external(os.path.join(root, task, \"combine\", split, \"external_features.csv\"), \n",
    "                os.path.join(\"/homes/syli/dataset/EC_all/result\", task, \"combine\", split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LNM\n",
      "intra AUC: 0.7222\n",
      "merge AUC: 0.7222\n",
      "peri AUC: 0.6667\n",
      "LVSI\n",
      "intra AUC: 0.6250\n",
      "merge AUC: 0.6250\n",
      "peri AUC: 0.5833\n"
     ]
    }
   ],
   "source": [
    "from atuo_radiomics.Metric import EstimatePrediction\n",
    "for task in tasks:\n",
    "    print(task)\n",
    "    for split in splits:\n",
    "        df = pd.read_csv(os.path.join(root, task, \"combine\", split, \"external_prediction.csv\"))\n",
    "        train_df = pd.read_csv(os.path.join(\"/homes/syli/dataset/EC_all/result\", task, \"combine\", split, \"train_prediction.csv\"))\n",
    "        #new_df =pd.concat((df.loc[:10],df.loc[18:]))\n",
    "        new_df = df.loc[:10]\n",
    "        #print(new_df.head())\n",
    "        train_metrics = EstimatePrediction(train_df[\"Pred\"].values, train_df[\"label\"].values.astype(int))\n",
    "        metrics = EstimatePrediction(new_df[\"Pred\"].values, new_df[\"label\"].values.astype(int), \"\", eval(train_metrics[\"Cutoff\"]))\n",
    "        print(split, \"AUC:\", metrics[\"AUC\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
